# Proyecto #1 Flujos de ejecuci√≥n
## Descripci√≥n
Client: Ministerio de Educaci√≥n de la Naci√≥n
Situaci√≥n inicial
üìç
Somos un equipo de desarrollo y data analytics, que trabajamos para la consultora ‚ÄúMyData‚Äù
y nuestro l√≠der t√©cnico nos comparte un pedido comercial directamente del Consejo Nacional
de Calidad de la Educaci√≥n (por sus siglas, CNCE).
El CNCE es un grupo deliberante que pertenece al Ministerio de Educaci√≥n de la Naci√≥n
Argentina. 
Este se encuentra analizando opciones universitarias disponibles en los √∫ltimos 10
a√±os para comparar datos extra√≠dos de universidades de todo el pa√≠s, p√∫blicas y privadas,
con el fin de tener una muestra representativa que facilite el an√°lisis.
Para esto, compartieron a ‚ÄúMyData‚Äù informaci√≥n disponible de m√°s de 15 universidades y
centros educativos con gran volumen de datos sensibles sobre las inscripciones de alumnos.
El CNCE requiere que preparemos el set de datos para que puedan analizar la informaci√≥n
relevante y tomar directrices en cuanto a qu√© carreras universitarias requieren programa de
becas, qu√© planes de estudios tienen adhesi√≥n, entre otros.
Tu objetivo
üìã Como parte de un equipo de desarrollo y data analytics de ‚ÄúMyData‚Äù, deber√°s analizar y
preparar flujos de ejecuci√≥n del set de datos recibido para obtener las comparaciones y
mediciones requeridas por el CNCE.

Requerimientos üîß

‚óè El Ministerio necesita que ordenemos los datos para obtener un archivo con s√≥lo la
informaci√≥n necesaria de cierto periodo de tiempo y de determinados lugares
geogr√°ficos de una base de datos SQL (las especificaciones ser√°n vistas en la primera
reuni√≥n de equipo). Ser√° necesario generar un diagrama de base de datos para que se
comprenda la estructura.

‚óè Los datos deben ser procesados de manera que se puedan ejecutar consultas a dos
universidades del total disponible para hacer an√°lisis parciales. Para esto ser√°
necesario realizar DAGs con Airflow que permitan procesar datos con Python y
consultas SQL.

‚óè Calcular, evaluar y ajustar formatos de determinados datos como fechas, nombres,
c√≥digos postales seg√∫n requerimientos normalizados que se especifican para cada
grupo de universidades, utilizando Pandas.
Assets üé®

La base de datos con la informaci√≥n que reuni√≥ el Ministerio de Educaci√≥n se encuentra aqu√≠:

‚óè A definir en el transcurso del proyecto.

El archivo auxiliar de c√≥digos postales se encuentra haciendo click aqu√≠.

https://drive.google.com/file/d/1or8pr7-XRVf5dIbRblSKlRmcP0wiP9QJ/view


## Requerimientos:
- Apache-Airflow 2.2.2
- Python 3.6
## Modulos utilizados en Python
- pathlib
- logging
- pandas
- datetime
- os
- sqlalchemy

## Enlaces:
- Guia de instalaci√≥n de Apache Airflow en Ubuntu: https://unixcop.com/how-to-install-apache-airflow-on-ubuntu-20

## Estructura y flujo de ejecuci√≥n
  Se generaron archivos ".sql" con las consultas correspondientes a cada centro educativo, normalizando las columnas tenidas en cuenta
  Mediante operadores disponibles en apache airflow (Python operators y postgre operators, se toman las consultas ".sql" para obtener los datos de la       base de datos provista. Estos datos se transorman mediante la libreria pandas, y se almacenan en forma local como archivos ".txt".
  Finalmete, a traves de las herramientas provistas por AWS (operadores y hooks S3), los datos almacenados como ".txt" son transformados a strings, y       almacenados en el servicio S3.

